# ‚ö° Guide Rapide : Passer √† Ollama

## üéØ En 3 √âtapes

### 1Ô∏è‚É£ Installer Ollama

**Windows** :
1. T√©l√©chargez : https://ollama.com/download/windows
2. Installez et lancez Ollama
3. T√©l√©chargez un mod√®le :
   ```powershell
   ollama pull llama3.2
   ```

### 2Ô∏è‚É£ Configuration D√©j√† Faite ‚úÖ

J'ai d√©j√† :
- ‚úÖ Ajout√© la d√©pendance Ollama dans `pom.xml`
- ‚úÖ Configur√© `application.properties` pour utiliser Ollama
- ‚úÖ Comment√© la configuration OpenAI

### 3Ô∏è‚É£ Red√©marrer

1. **V√©rifiez qu'Ollama est d√©marr√©** (il devrait l'√™tre apr√®s l'installation)
2. **Red√©marrez Chatboot**
3. **Testez** : `http://localhost:8087/api/chat?query=Bonjour`

## ‚úÖ C'est Tout !

Votre chatbot fonctionne maintenant avec Ollama (gratuit) au lieu d'OpenAI.

## üß™ V√©rifier qu'Ollama Fonctionne

```powershell
# V√©rifier les mod√®les install√©s
ollama list

# Tester Ollama directement
ollama run llama3.2 "Bonjour"
```

## üìù Mod√®les Recommand√©s

- **`llama3.2`** - Rapide et efficace (recommand√© pour commencer)
- **`mistral`** - Bon pour le fran√ßais
- **`phi3`** - Tr√®s rapide, l√©ger

Pour changer de mod√®le, modifiez dans `application.properties` :
```properties
spring.ai.ollama.chat.options.model=llama3.2
```

## üÜò Probl√®me ?

Si vous avez une erreur "Connection refused" :
1. V√©rifiez qu'Ollama est d√©marr√©
2. V√©rifiez que le mod√®le est t√©l√©charg√© : `ollama pull llama3.2`
3. Red√©marrez Chatboot

Consultez `CONFIGURER_OLLAMA.md` pour plus de d√©tails.


